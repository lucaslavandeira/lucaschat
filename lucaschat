#!/usr/bin/env python3
import os
import sys
import time
import requests
from prompt_toolkit import PromptSession
from prompt_toolkit.keys import Keys
from prompt_toolkit.key_binding import KeyBindings
try:
    import tomllib
except ImportError:
    import toml as tomllib

def main():
    cpath = os.path.expanduser("~/.config/chat.toml")
    with open(cpath, "rb") as f:
        conf = tomllib.load(f)
    key = conf["openai"]["api_key"]
    model = conf["openai"].get("model", "gpt-4")
    system_prompt = conf["openai"].get("system_prompt", "")
    history_len = int(conf["openai"].get("history_length", 5))
    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {key}", "Content-Type": "application/json"}
    messages = [{"role": "system", "content": system_prompt}]

    bindings = KeyBindings()

    @bindings.add(Keys.Enter)
    def _(event):
        if "s-" in event.key_sequence[0].key:  # Detect Shift+Enter
            event.current_buffer.insert_text("\n")
        else:
            event.current_buffer.validate_and_handle()

    session = PromptSession(key_bindings=bindings, multiline=True)

    try:
        while True:
            user_input = session.prompt("> ").strip()
            if not user_input:
                continue
            messages.append({"role": "user", "content": user_input})
            while len(messages) > 2 * history_len + 1:
                messages.pop(1)
            data = {"model": model, "messages": messages}
            r = requests.post(url, headers=headers, json=data, timeout=30)
            if r.status_code == 429:
                print("Rate limited, retrying...")
                time.sleep(3)
                continue
            r.raise_for_status()
            resp = r.json()["choices"][0]["message"]["content"]
            print(resp)
            messages.append({"role": "assistant", "content": resp})
    except EOFError:
        print("\nExiting.")
        sys.exit(0)

if __name__ == "__main__":
    main()
