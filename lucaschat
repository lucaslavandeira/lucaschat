#!/usr/bin/env python3
import os
import sys
import time
import requests
from prompt_toolkit import PromptSession
try:
    import tomllib
except ImportError:
    import toml as tomllib

def main():
    cpath = os.path.expanduser("~/.config/chat.toml")
    with open(cpath, "rb") as f:
        conf = tomllib.load(f)
    key = conf["openai"]["api_key"]
    model = conf["openai"].get("model", "gpt-4")
    system_prompt = conf["openai"].get("system_prompt", "")
    history_len = int(conf["openai"].get("history_length", 5))
    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {key}", "Content-Type": "application/json"}
    messages = [{"role": "system", "content": system_prompt}]
    session = PromptSession()

    while True:
        user_input = session.prompt("> ", multiline=True).strip()
        if not user_input:
            continue
        messages.append({"role": "user", "content": user_input})
        while len(messages) > 2 * history_len + 1:
            messages.pop(1)
        data = {"model": model, "messages": messages}
        try:
            r = requests.post(url, headers=headers, json=data, timeout=30)
            if r.status_code == 429:
                print("Rate limited, retrying...")
                time.sleep(3)
                continue
            r.raise_for_status()
            resp = r.json()["choices"][0]["message"]["content"]
            print(resp)
            messages.append({"role": "assistant", "content": resp})
        except Exception as e:
            print(f"Error: {e}")
            time.sleep(3)

if __name__ == "__main__":
    main()
